{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Correction*: K Nearest Neighbor Regression\n",
    "1. Find k training instances with most similar input attributes.\n",
    "2. Compute the average of their target value\n",
    "3. Assign the average as the prediction on the new data instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Schedule\n",
    "**Stage 1 (deadline 04/24)**\n",
    "\n",
    "- Form a team of 1-3 students (3-student team is only allowed if the project is significantly more complex than the mid-term project)\n",
    "- Describe the background of the problem,\n",
    "- Describe where to get the data,\n",
    "- Frame the Machine Learning problem: What are input features? What are the model expected to learn? Is it supervised learning / unsupervised learning? Is it a classification / regression problem?\n",
    "- Describe briefly the research plan: what models to use? How to measure the performance?\n",
    "\n",
    "**Stage 2(deadline 05/08)**\n",
    "Progress report\n",
    "\n",
    "\n",
    "**Stage 3(deadline 05/25)**\n",
    "Final report\n",
    "\n",
    "** Online data sets**\n",
    "- [Kaggle.com](kaggle.com): Gain access to their data set by entering a competition\n",
    "- [UCI machine learning repository](http://mlr.cs.umass.edu/ml/) is one of the oldest sources of data sets on the web. These data sets tend to be fairly small, but are usually clean and ready for machine learning to be applied.\n",
    "\n",
    "**Backup project: Implementing a neural network from scratch**\n",
    "1. Use numpy library to build a neural network class with fit() and predict() method\n",
    "2. Use the class to construct a neural network model for MNIST classification.\n",
    "3. Build the same model with TensorFlow, compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 \n",
    "# Up and Running with TensorFlow\n",
    "\n",
    "TensorFlow is an open source software library for high performance numerical computation.\n",
    "- Originally it was developed by Google Brain team, and now it is one of the most popular open source projects on GitHub (check out https://github.com/jtoy/awesome-tensorflow)\n",
    "- Its basic principle is simple: first define in Python a graph of computations to perform, and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.\n",
    "![](Data/tf_1.png)\n",
    "- TensorFlow can break up the graph into several chuncks and run them in parallel across multiple CPUs , GPUs, Tensor Processing Units (TPUs), and from desktops to clusters of servers to mobile and edge devices.\n",
    "- It comes with a great visualization tool called TensorBoard that allows you to browse through the computation graph, view learning curves, and more.\n",
    "- Google also launched a cloud service to run TensorFlow computational graphs (cloud.google.com/ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Since TensorFlow depends on several other libraries and it is being updated regularly, this library is best to be installed in an isolated environment to avoid version conflicts. There are several different ways to install, depending on the operating system, TensorFlow version, and personal preference (See page 232 of textbook, and www.tensorflow.org/install). Here I provide the simplest way to install TensorFlow via Anaconda:\n",
    "1. Open Anaconda Navigator\n",
    "2. Create a new environment (name it tensorflow)\n",
    "3. Find tensorflow library from the list of uninstalled libraries; install tensorflow.\n",
    "4. Go back to Home, change \"base(root)\" to \"tensorflow\", then install Jupyter Notebook.\n",
    "\n",
    "When you finished installing, launch Jupyter Notebook in tensorflow environment and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test code for tensorflow installation\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a constant string\n",
    "hello = tf.constant('hello')  \n",
    "# Create a TensorFlow session\n",
    "sess = tf.Session()\n",
    "# Print the string during a session run\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow Graph\n",
    "TensorFlow uses a **dataflow graph** to represent your computation in terms of the dependencies between individual operations. This leads to a three-step programming procedure:\n",
    "1. Define the dataflow graph\n",
    "2. Create a TensorFlow **session**\n",
    "3. Run the graph\n",
    "\n",
    "A TensorFlow session will take care of placing the operation onto devices such as CPUs and GPUs and running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines a dataflow graph\n",
    "\n",
    "# Define two variables x, y\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "\n",
    "# Define f based on x and y\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "# The following print statement only gives the \n",
    "# description of variable f, not its value (since\n",
    "# the value hasn't been computed yet)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow session and evaluates f\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize x and y\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "\n",
    "# Evaluate f\n",
    "result = sess.run(f)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to repeat sess.run() all the time is cumbersome. Here is a better way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use with statement to set sess as default session\n",
    "with tf.Session() as sess:\n",
    "    # equivalent to sess.run(x.initializer):\n",
    "    x.initializer.run() \n",
    "    # equivalent to sess.run(y.initializer):\n",
    "    y.initializer.run()\n",
    "    # equivalent to sess.run(f)\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"global_variables_initializer()\" to set up a node in the graph that initializes all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare an node to initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only one session is needed, it is preferable to create an **InteractiveSession**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: Basic Arithmetic with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow graph to compute\n",
    "# S = pi * r ** 2\n",
    "# where pi=3.14, r=1.0\n",
    "\n",
    "# IMPORTANT: reset the graph!\n",
    "tf.reset_default_graph()\n",
    "\n",
    "pi = tf.Variable(3.14)\n",
    "r = tf.Variable(1.0)\n",
    "S = pi * r**2\n",
    "\n",
    "# Method 1: Interactive Session\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess = tf.InteractiveSession()\n",
    "# init.run() # means variables are initialized\n",
    "# print(S.eval())\n",
    "# sess.close()\n",
    "\n",
    "# Method 2: Use a with block to do computation\n",
    "with tf.Session() as sess:\n",
    "    pi.initializer.run() \n",
    "    r.initializer.run()\n",
    "    print(S.eval())\n",
    "# do not need to close the session; common way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow graph to compute\n",
    "# x1 = -b + sqrt(b^2 - 4*c)\n",
    "# x2 = -b - sqrt(b^2 - 4*c)\n",
    "# where b = 2.0, c = 0.5\n",
    "# use tf.sqrt() to compute square root\n",
    "\n",
    "b = tf.Variable(2.0)\n",
    "c = tf.Variable(0.5)\n",
    "x1 = -b + tf.sqrt(b**2 - 4*c)\n",
    "x2 = -b - tf.sqrt(b**2 - 4*c)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    b.initializer.run() \n",
    "    c.initializer.run()\n",
    "    print(x1.eval(),x2.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Matrix Math functions:\n",
    "# use tf.diag() to create a diagonal matrix with\n",
    "# diagonal [1, 2, 3, 4]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "matrix = tf.diag([1,2,3,4])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(matrix.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define two random matrix of size 2*2 using \n",
    "# numpy.random.rand(). Calculate their matrix \n",
    "# product.\n",
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "a = np.matrix(numpy.random.rand(2,2))\n",
    "b = np.matrix(numpy.random.rand(2,2))\n",
    "\n",
    "prod = tf.Variable(np.matmul(a,b))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(prod.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a matrix [[1, 2], [3, 4]], obtain \n",
    "# its transpose with tf.transpose()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "matrix = tf.Variable([[1,2],[3,4]], dtype=tf.float32)\n",
    "trans = tf.transpose(matrix)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(trans.eval())\n",
    "# find its inverse, and verify that their product\n",
    "# is the identity matrix.\n",
    "# Remark: add argument dtype=tf.float32 to convert\n",
    "# int numbers to floating point numbers.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "matrix = tf.Variable([[1,2],[3,4]], dtype=tf.float32)\n",
    "inverse = tf.matrix_inverse(matrix) \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(inverse.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solve the linear system of equation with\n",
    "# tf.matrix_solve()\n",
    "# 1*x1 + 2*x2 = 1\n",
    "# 3*x1 + 4*x2 = 5\n",
    "\n",
    "m1 = 1*x1 + 2*x2 = 1\n",
    "m2 = 3*x1 + 4*x2 = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a node value\n",
    "When you evaluate a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first. Then node values are dropped except the values of final variables. Thus it will be more efficient to evaluate variables in one graph run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "# w, x will be evaluated before evaluating y\n",
    "print(y.eval())\n",
    "# w, x will be evaluated again to evalute z\n",
    "print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A more efficient way\n",
    "y_val, z_val = sess.run([y, z])\n",
    "print(y_val, z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Linear Regression with Normal Equation\n",
    "\n",
    "Let's apply linear regression to the california housing data that we analyzed before. Late we will compare its TensorFlow implementation with sklearn and numpy implementations.\n",
    "\n",
    "#### Linear Regression with Multiple Variables\n",
    "1. Input features: $\\textbf{x} = (x_1,...,x_n)$.\n",
    "2. Target value: $y$.\n",
    "3. Training set: $\\{(\\textbf{x}^{(i)}, y^{(i)}), i=1,...,m\\}$.\n",
    "4. Linear model: $y = \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n + b$.\n",
    "\n",
    "#### Normal Equation\n",
    "1. For each $x^{(i)}$, add a constant 1 at the start of the vector. For example, if $x = (10, 20, 30)$, new vector should be $(1, 10, 20, 30)$.\n",
    "2. Stack all transformed input vectors vertically, resulting in a matrix $X$.\n",
    "3. Stack all target values vertically, resulting in a vector $y$.\n",
    "4. Apply formula\n",
    "\n",
    "$\\theta = (X^T\\cdot X)^{-1}\\cdot X^T\\cdot y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the calculation with numpy\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the calculation with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use sklearn to find the result of regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data to the graph\n",
    "We can use tf.placeholder() to delay initialization. This is particularly useful when we want to feed data to the graph during execution. The following code creates a placeholder node A, and B = A + 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "# None as a dimension means any size.\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
