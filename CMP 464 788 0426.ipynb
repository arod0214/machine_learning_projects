{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with TensorFlow\n",
    "\n",
    "TensorFlow has a cool interactive visualization tool of neural netowrks called [*Deep Playground*](http://playground.tensorflow.org). Let's try to config a good neural network for the four classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tf.learn\n",
    "TensorFlow's high-level machine learning API (tf.learn) makes it easy to configure, train, and evaluate a variety of machine learning models. Here we are going to use DNNClassifier to build a classifier for MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-7a719a86c2f3>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('tmp/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype('int')\n",
    "y_test = mnist.test.labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8f6f4efeb4b9>:4: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-8f6f4efeb4b9>:7: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:142: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:182: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1165: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Amanda\\AppData\\Local\\Temp\\tmpo11v2ptl\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_task_id': 0, '_save_summary_steps': 100, '_is_chief': True, '_keep_checkpoint_max': 5, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A157B1AF28>, '_keep_checkpoint_every_n_hours': 10000, '_environment': 'local', '_num_worker_replicas': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_model_dir': 'C:\\\\Users\\\\Amanda\\\\AppData\\\\Local\\\\Temp\\\\tmpo11v2ptl', '_evaluation_master': '', '_tf_random_seed': 42, '_num_ps_replicas': 0, '_task_type': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600}\n",
      "WARNING:tensorflow:From <ipython-input-3-8f6f4efeb4b9>:16: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Amanda\\AppData\\Local\\Temp\\tmpo11v2ptl\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2865598, step = 1\n",
      "INFO:tensorflow:global_step/sec: 144.688\n",
      "INFO:tensorflow:loss = 0.3356965, step = 101 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.568\n",
      "INFO:tensorflow:loss = 0.27752522, step = 201 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.225\n",
      "INFO:tensorflow:loss = 0.40996167, step = 301 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.957\n",
      "INFO:tensorflow:loss = 0.2354286, step = 401 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.269\n",
      "INFO:tensorflow:loss = 0.23480539, step = 501 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.374\n",
      "INFO:tensorflow:loss = 0.07679458, step = 601 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.911\n",
      "INFO:tensorflow:loss = 0.12395301, step = 701 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.798\n",
      "INFO:tensorflow:loss = 0.25859508, step = 801 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.229\n",
      "INFO:tensorflow:loss = 0.10696796, step = 901 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.361\n",
      "INFO:tensorflow:loss = 0.18983993, step = 1001 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.791\n",
      "INFO:tensorflow:loss = 0.19446522, step = 1101 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.123\n",
      "INFO:tensorflow:loss = 0.18852936, step = 1201 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.275\n",
      "INFO:tensorflow:loss = 0.16103908, step = 1301 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.486\n",
      "INFO:tensorflow:loss = 0.09094427, step = 1401 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.913\n",
      "INFO:tensorflow:loss = 0.103921935, step = 1501 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.82\n",
      "INFO:tensorflow:loss = 0.17371443, step = 1601 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.546\n",
      "INFO:tensorflow:loss = 0.032240126, step = 1701 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.909\n",
      "INFO:tensorflow:loss = 0.14544253, step = 1801 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.61\n",
      "INFO:tensorflow:loss = 0.08865458, step = 1901 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.015\n",
      "INFO:tensorflow:loss = 0.09173921, step = 2001 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.276\n",
      "INFO:tensorflow:loss = 0.022405948, step = 2101 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.854\n",
      "INFO:tensorflow:loss = 0.04230074, step = 2201 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.703\n",
      "INFO:tensorflow:loss = 0.063277684, step = 2301 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.871\n",
      "INFO:tensorflow:loss = 0.04287714, step = 2401 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.672\n",
      "INFO:tensorflow:loss = 0.065549284, step = 2501 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.815\n",
      "INFO:tensorflow:loss = 0.038846284, step = 2601 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.995\n",
      "INFO:tensorflow:loss = 0.027449423, step = 2701 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.067\n",
      "INFO:tensorflow:loss = 0.06458164, step = 2801 (0.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.078\n",
      "INFO:tensorflow:loss = 0.158137, step = 2901 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.69\n",
      "INFO:tensorflow:loss = 0.017249214, step = 3001 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.159\n",
      "INFO:tensorflow:loss = 0.04993702, step = 3101 (0.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.658\n",
      "INFO:tensorflow:loss = 0.013365817, step = 3201 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.422\n",
      "INFO:tensorflow:loss = 0.028932435, step = 3301 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.355\n",
      "INFO:tensorflow:loss = 0.20596625, step = 3401 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.258\n",
      "INFO:tensorflow:loss = 0.11780959, step = 3501 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.864\n",
      "INFO:tensorflow:loss = 0.14953183, step = 3601 (0.641 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 156.746\n",
      "INFO:tensorflow:loss = 0.040167615, step = 3701 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.487\n",
      "INFO:tensorflow:loss = 0.004427076, step = 3801 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.262\n",
      "INFO:tensorflow:loss = 0.07642931, step = 3901 (0.640 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\Amanda\\AppData\\Local\\Temp\\tmpo11v2ptl\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.032751523.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the neural network\n",
    "\n",
    "# set random seed\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "\n",
    "# define input features\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "model = tf.contrib.learn.DNNClassifier(\n",
    "    hidden_units=[300, 100],\n",
    "    n_classes=10,\n",
    "    feature_columns=feature_cols,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# make the class similar to an sklearn class\n",
    "model = tf.contrib.learn.SKCompat(model)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=50,\n",
    "          steps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Amanda\\AppData\\Local\\Temp\\tmpo11v2ptl\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "keys: dict_keys(['logits', 'probabilities', 'classes'])\n",
      "classes for first 10 images: [7 2 1 0 4 1 4 9 5 9]\n",
      "accuracy: 0.976500%\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('keys:', y_pred.keys())\n",
    "print('classes for first 10 images:', y_pred['classes'][:10])\n",
    "\n",
    "# compute accuracy\n",
    "acc = sum(y_pred['classes'] == y_test) / len(y_test)\n",
    "print('accuracy: {0:f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tf.estimator.DNNClassifier (For TensorFlow 1.3+)\n",
    "\n",
    "\n",
    "**Note**: The textbook uses tf.learn.DNNClassifier, which is replaced by tf.estimator.DNNClassifier. The code from textbook is still working, but you will get a warning when running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_task_id': 0, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A1591BF0B8>, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_service': None, '_model_dir': './mnist', '_evaluation_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_task_type': 'worker', '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./mnist\\model.ckpt.\n",
      "INFO:tensorflow:loss = 113.55842, step = 1\n",
      "INFO:tensorflow:global_step/sec: 128.475\n",
      "INFO:tensorflow:loss = 12.305484, step = 101 (0.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.33\n",
      "INFO:tensorflow:loss = 14.780908, step = 201 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.647\n",
      "INFO:tensorflow:loss = 13.123988, step = 301 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.041\n",
      "INFO:tensorflow:loss = 14.170203, step = 401 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.281\n",
      "INFO:tensorflow:loss = 9.719006, step = 501 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.787\n",
      "INFO:tensorflow:loss = 5.8106127, step = 601 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.649\n",
      "INFO:tensorflow:loss = 0.49137616, step = 701 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.355\n",
      "INFO:tensorflow:loss = 4.9412827, step = 801 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.321\n",
      "INFO:tensorflow:loss = 5.1283, step = 901 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.976\n",
      "INFO:tensorflow:loss = 5.18332, step = 1001 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.533\n",
      "INFO:tensorflow:loss = 3.2278898, step = 1101 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.711\n",
      "INFO:tensorflow:loss = 5.510518, step = 1201 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.394\n",
      "INFO:tensorflow:loss = 5.0673914, step = 1301 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.298\n",
      "INFO:tensorflow:loss = 7.0119705, step = 1401 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.728\n",
      "INFO:tensorflow:loss = 8.991961, step = 1501 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.791\n",
      "INFO:tensorflow:loss = 3.3387525, step = 1601 (0.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.393\n",
      "INFO:tensorflow:loss = 1.5080756, step = 1701 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.373\n",
      "INFO:tensorflow:loss = 3.5026324, step = 1801 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.781\n",
      "INFO:tensorflow:loss = 3.6970549, step = 1901 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.138\n",
      "INFO:tensorflow:loss = 1.0883654, step = 2001 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.717\n",
      "INFO:tensorflow:loss = 8.324868, step = 2101 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.075\n",
      "INFO:tensorflow:loss = 4.27594, step = 2201 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.685\n",
      "INFO:tensorflow:loss = 10.248574, step = 2301 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.424\n",
      "INFO:tensorflow:loss = 1.6693374, step = 2401 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.979\n",
      "INFO:tensorflow:loss = 6.2541184, step = 2501 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.839\n",
      "INFO:tensorflow:loss = 4.7088428, step = 2601 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.306\n",
      "INFO:tensorflow:loss = 1.588719, step = 2701 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.821\n",
      "INFO:tensorflow:loss = 8.481005, step = 2801 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.724\n",
      "INFO:tensorflow:loss = 12.130206, step = 2901 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.211\n",
      "INFO:tensorflow:loss = 2.075332, step = 3001 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.342\n",
      "INFO:tensorflow:loss = 0.655035, step = 3101 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.47\n",
      "INFO:tensorflow:loss = 3.3319366, step = 3201 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.245\n",
      "INFO:tensorflow:loss = 0.8718398, step = 3301 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.589\n",
      "INFO:tensorflow:loss = 0.8072555, step = 3401 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.88\n",
      "INFO:tensorflow:loss = 5.2953887, step = 3501 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.41\n",
      "INFO:tensorflow:loss = 0.89052534, step = 3601 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.132\n",
      "INFO:tensorflow:loss = 2.0423186, step = 3701 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.066\n",
      "INFO:tensorflow:loss = 1.182007, step = 3801 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.528\n",
      "INFO:tensorflow:loss = 0.24414365, step = 3901 (0.707 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./mnist\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.69614106.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a1591bf3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the neural network\n",
    "\n",
    "# Set input to be 28*28 \n",
    "feature_cols = [tf.feature_column.numeric_column(\n",
    "    'x', shape=[28, 28])]\n",
    "\n",
    "# Create two hidden layers with 300 and 100 neurons\n",
    "dnn_clf = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_cols,\n",
    "    hidden_units=[300, 100],\n",
    "    n_classes=10,\n",
    "    model_dir='./mnist'\n",
    ")\n",
    "\n",
    "# configure training input\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x':X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=None,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# use train() method to train the model\n",
    "dnn_clf.train(input_fn=train_input_fn,\n",
    "              steps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-26-17:34:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-26-17:34:10\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9729, average_loss = 0.08584396, global_step = 4000, loss = 10.866323\n",
      "Test Accuracy: 97.289997%\n"
     ]
    }
   ],
   "source": [
    "# Define test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x':X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Compute accuracy\n",
    "evaluation = dnn_clf.evaluate(input_fn=test_input_fn)\n",
    "accuracy = evaluation['accuracy']\n",
    "print('Test Accuracy: {0:f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Keras\n",
    "\n",
    "Keras is a powerful easy-to-use Python library for developing and evaluating deep neural network models. It wraps the efficient numerical computation library TensorFlow and allows you to define and train neural network models in a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from keras import backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Dense(300, activation='relu')(img)\n",
    "x2 = Dense(100, activation='relu')(x1)\n",
    "preds = Dense(10, activation='softmax')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Amanda\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0 accuracy: 0.9673\n",
      "1 accuracy: 0.9688\n",
      "2 accuracy: 0.9738\n",
      "3 accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "acc = accuracy(labels, preds)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 4\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(len(mnist_data.train.images) // batch_size):\n",
    "            batch = mnist_data.train.next_batch(batch_size)\n",
    "            train_step.run(feed_dict={img: batch[0],\n",
    "                                      labels: batch[1]})\n",
    "        acc_val = acc.eval(feed_dict={img:mnist_data.test.images,\n",
    "                                  labels:mnist_data.test.labels})\n",
    "        print(epoch, 'accuracy:', sum(acc_val)/len(acc_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using plain TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32,\n",
    "                   shape=(None, n_inputs),\n",
    "                   name='x')\n",
    "y = tf.placeholder(tf.int64,\n",
    "                   shape=(None),\n",
    "                   name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal(\n",
    "            (n_inputs, n_neurons),\n",
    "            stddev=stddev\n",
    "        )\n",
    "        W = tf.Variable(init, name='weights')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]),\n",
    "                        name='bias')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        return activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(\n",
    "        X,\n",
    "        n_hidden1,\n",
    "        name='hidden1',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    hidden2 = neuron_layer(\n",
    "        hidden1,\n",
    "        n_hidden2,\n",
    "        name='hidden2',\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    logits = neuron_layer(\n",
    "        hidden2,\n",
    "        n_outputs,\n",
    "        name='outputs',\n",
    "        activation=tf.identity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=logits\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy,\n",
    "                          name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate\n",
    "    )\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(correct, tf.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9113\n",
      "1 Accuracy: 0.9279\n",
      "2 Accuracy: 0.9372\n",
      "3 Accuracy: 0.9442\n",
      "4 Accuracy: 0.9469\n",
      "5 Accuracy: 0.9541\n",
      "6 Accuracy: 0.958\n",
      "7 Accuracy: 0.9578\n",
      "8 Accuracy: 0.9618\n",
      "9 Accuracy: 0.9611\n",
      "10 Accuracy: 0.9632\n",
      "11 Accuracy: 0.9643\n",
      "12 Accuracy: 0.9662\n",
      "13 Accuracy: 0.9674\n",
      "14 Accuracy: 0.9685\n",
      "15 Accuracy: 0.9695\n",
      "16 Accuracy: 0.9692\n",
      "17 Accuracy: 0.9697\n",
      "18 Accuracy: 0.9698\n",
      "19 Accuracy: 0.9707\n",
      "20 Accuracy: 0.9711\n",
      "21 Accuracy: 0.9713\n",
      "22 Accuracy: 0.9731\n",
      "23 Accuracy: 0.9722\n",
      "24 Accuracy: 0.9734\n",
      "25 Accuracy: 0.9749\n",
      "26 Accuracy: 0.975\n",
      "27 Accuracy: 0.9754\n",
      "28 Accuracy: 0.9748\n",
      "29 Accuracy: 0.9753\n",
      "30 Accuracy: 0.9757\n",
      "31 Accuracy: 0.9755\n",
      "32 Accuracy: 0.975\n",
      "33 Accuracy: 0.9758\n",
      "34 Accuracy: 0.9761\n",
      "35 Accuracy: 0.9769\n",
      "36 Accuracy: 0.9772\n",
      "37 Accuracy: 0.976\n",
      "38 Accuracy: 0.9766\n",
      "39 Accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op,\n",
    "                     feed_dict={X: X_batch,\n",
    "                                y: y_batch})\n",
    "        acc = accuracy.eval(\n",
    "            feed_dict={X: X_test,\n",
    "                       y: y_test}\n",
    "        )\n",
    "        print(epoch, 'Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
